{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b0f2a67-2f03-4ced-b931-f6130fa9405f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Loaded 8501 rows after cleaning\n",
      "‚úÖ Loaded 8499 feature vectors\n",
      "‚öôÔ∏è FAISS index built with 8499 vectors\n",
      "\n",
      "üîÑ Running retrieval for 8159 queries...\n",
      "‚úÖ Saved: 5787_ELITE_CODERS_CLIP.png\n",
      "‚úÖ Saved: 1_ELITE_CODERS_CLIP.png\n",
      "‚úÖ Saved: 2_ELITE_CODERS_CLIP.png\n",
      "‚úÖ Saved: 3_ELITE_CODERS_CLIP.png\n",
      "‚úÖ Saved: 4_ELITE_CODERS_CLIP.png\n",
      "‚úÖ Saved: 5_ELITE_CODERS_CLIP.png\n",
      "‚úÖ Saved: 2448_ELITE_CODERS_CLIP.png\n",
      "‚úÖ Saved: 7_ELITE_CODERS_CLIP.png\n",
      "‚úÖ Saved: 8_ELITE_CODERS_CLIP.png\n",
      "‚úÖ Saved: 8185_ELITE_CODERS_CLIP.png\n",
      "‚úÖ Saved: 10_ELITE_CODERS_CLIP.png\n",
      "‚úÖ Saved: 11_ELITE_CODERS_CLIP.png\n",
      "‚úÖ Saved: 12_ELITE_CODERS_CLIP.png\n",
      "‚úÖ Saved: 8404_ELITE_CODERS_CLIP.png\n",
      "‚úÖ Saved: 14_ELITE_CODERS_CLIP.png\n",
      "‚úÖ Saved: 691_ELITE_CODERS_CLIP.png\n",
      "‚úÖ Saved: 16_ELITE_CODERS_CLIP.png\n",
      "‚úÖ Saved: 17_ELITE_CODERS_CLIP.png\n",
      "‚úÖ Saved: 18_ELITE_CODERS_CLIP.png\n",
      "‚úÖ Saved: 19_ELITE_CODERS_CLIP.png\n",
      "‚úÖ Saved: 20_ELITE_CODERS_CLIP.png\n",
      "‚úÖ Saved: 21_ELITE_CODERS_CLIP.png\n",
      "‚úÖ Saved: 615_ELITE_CODERS_CLIP.png\n",
      "‚úÖ Saved: 23_ELITE_CODERS_CLIP.png\n",
      "‚úÖ Saved: 24_ELITE_CODERS_CLIP.png\n",
      "‚úÖ Saved: 522_ELITE_CODERS_CLIP.png\n",
      "‚úÖ Saved: 26_ELITE_CODERS_CLIP.png\n",
      "‚úÖ Saved: 6634_ELITE_CODERS_CLIP.png\n",
      "‚úÖ Saved: 6974_ELITE_CODERS_CLIP.png\n",
      "‚úÖ Saved: 398_ELITE_CODERS_CLIP.png\n",
      "‚úÖ Saved: 30_ELITE_CODERS_CLIP.png\n",
      "‚úÖ Saved: 31_ELITE_CODERS_CLIP.png\n",
      "‚úÖ Saved: 32_ELITE_CODERS_CLIP.png\n",
      "‚úÖ Saved: 33_ELITE_CODERS_CLIP.png\n",
      "‚úÖ Saved: 34_ELITE_CODERS_CLIP.png\n",
      "‚úÖ Saved: 35_ELITE_CODERS_CLIP.png\n",
      "‚úÖ Saved: 36_ELITE_CODERS_CLIP.png\n",
      "‚úÖ Saved: 115_ELITE_CODERS_CLIP.png\n",
      "‚úÖ Saved: 38_ELITE_CODERS_CLIP.png\n",
      "‚úÖ Saved: 39_ELITE_CODERS_CLIP.png\n",
      "‚úÖ Saved: 5749_ELITE_CODERS_CLIP.png\n",
      "‚úÖ Saved: 41_ELITE_CODERS_CLIP.png\n",
      "‚úÖ Saved: 42_ELITE_CODERS_CLIP.png\n",
      "‚úÖ Saved: 43_ELITE_CODERS_CLIP.png\n",
      "‚úÖ Saved: 44_ELITE_CODERS_CLIP.png\n",
      "‚úÖ Saved: 45_ELITE_CODERS_CLIP.png\n",
      "‚úÖ Saved: 4123_ELITE_CODERS_CLIP.png\n",
      "‚úÖ Saved: 1476_ELITE_CODERS_CLIP.png\n",
      "‚úÖ Saved: 48_ELITE_CODERS_CLIP.png\n",
      "‚úÖ Saved: 49_ELITE_CODERS_CLIP.png\n",
      "‚úÖ Saved: 50_ELITE_CODERS_CLIP.png\n",
      "‚úÖ Saved: 51_ELITE_CODERS_CLIP.png\n",
      "‚úÖ Saved: 52_ELITE_CODERS_CLIP.png\n",
      "‚úÖ Saved: 53_ELITE_CODERS_CLIP.png\n",
      "‚úÖ Saved: 54_ELITE_CODERS_CLIP.png\n",
      "‚úÖ Saved: 55_ELITE_CODERS_CLIP.png\n",
      "‚úÖ Saved: 56_ELITE_CODERS_CLIP.png\n",
      "‚úÖ Saved: 57_ELITE_CODERS_CLIP.png\n",
      "‚úÖ Saved: 58_ELITE_CODERS_CLIP.png\n",
      "‚úÖ Saved: 2388_ELITE_CODERS_CLIP.png\n",
      "‚úÖ Saved: 840_ELITE_CODERS_CLIP.png\n",
      "‚úÖ Saved: 61_ELITE_CODERS_CLIP.png\n",
      "‚úÖ Saved: 62_ELITE_CODERS_CLIP.png\n",
      "‚úÖ Saved: 63_ELITE_CODERS_CLIP.png\n",
      "‚úÖ Saved: 64_ELITE_CODERS_CLIP.png\n",
      "‚úÖ Saved: 65_ELITE_CODERS_CLIP.png\n",
      "‚úÖ Saved: 66_ELITE_CODERS_CLIP.png\n",
      "‚úÖ Saved: 67_ELITE_CODERS_CLIP.png\n",
      "‚úÖ Saved: 68_ELITE_CODERS_CLIP.png\n",
      "‚úÖ Saved: 840_ELITE_CODERS_CLIP.png\n",
      "‚úÖ Saved: 2115_ELITE_CODERS_CLIP.png\n",
      "‚úÖ Saved: 1003_ELITE_CODERS_CLIP.png\n",
      "‚úÖ Saved: 72_ELITE_CODERS_CLIP.png\n",
      "‚úÖ Saved: 73_ELITE_CODERS_CLIP.png\n",
      "‚úÖ Saved: 74_ELITE_CODERS_CLIP.png\n",
      "‚úÖ Saved: 75_ELITE_CODERS_CLIP.png\n",
      "‚úÖ Saved: 5683_ELITE_CODERS_CLIP.png\n",
      "‚úÖ Saved: 77_ELITE_CODERS_CLIP.png\n",
      "‚úÖ Saved: 78_ELITE_CODERS_CLIP.png\n",
      "‚úÖ Saved: 79_ELITE_CODERS_CLIP.png\n",
      "‚úÖ Saved: 6805_ELITE_CODERS_CLIP.png\n",
      "‚úÖ Saved: 81_ELITE_CODERS_CLIP.png\n",
      "‚úÖ Saved: 1827_ELITE_CODERS_CLIP.png\n",
      "‚úÖ Saved: 83_ELITE_CODERS_CLIP.png\n",
      "‚úÖ Saved: 684_ELITE_CODERS_CLIP.png\n",
      "‚úÖ Saved: 85_ELITE_CODERS_CLIP.png\n",
      "‚úÖ Saved: 7568_ELITE_CODERS_CLIP.png\n",
      "‚úÖ Saved: 87_ELITE_CODERS_CLIP.png\n",
      "‚úÖ Saved: 88_ELITE_CODERS_CLIP.png\n",
      "‚úÖ Saved: 89_ELITE_CODERS_CLIP.png\n",
      "‚úÖ Saved: 188_ELITE_CODERS_CLIP.png\n",
      "‚úÖ Saved: 91_ELITE_CODERS_CLIP.png\n",
      "‚úÖ Saved: 92_ELITE_CODERS_CLIP.png\n",
      "‚úÖ Saved: 93_ELITE_CODERS_CLIP.png\n",
      "‚úÖ Saved: 94_ELITE_CODERS_CLIP.png\n",
      "‚úÖ Saved: 95_ELITE_CODERS_CLIP.png\n",
      "‚úÖ Saved: 96_ELITE_CODERS_CLIP.png\n",
      "‚úÖ Saved: 97_ELITE_CODERS_CLIP.png\n",
      "‚úÖ Saved: 98_ELITE_CODERS_CLIP.png\n",
      "‚úÖ Saved: 1970_ELITE_CODERS_CLIP.png\n",
      "‚úÖ Saved: 100_ELITE_CODERS_CLIP.png\n",
      "‚úÖ Saved: 101_ELITE_CODERS_CLIP.png\n",
      "‚úÖ Saved: 102_ELITE_CODERS_CLIP.png\n",
      "‚úÖ Saved: 103_ELITE_CODERS_CLIP.png\n",
      "‚úÖ Saved: 104_ELITE_CODERS_CLIP.png\n",
      "‚úÖ Saved: 105_ELITE_CODERS_CLIP.png\n",
      "‚úÖ Saved: 106_ELITE_CODERS_CLIP.png\n",
      "‚úÖ Saved: 107_ELITE_CODERS_CLIP.png\n",
      "‚úÖ Saved: 108_ELITE_CODERS_CLIP.png\n",
      "‚úÖ Saved: 109_ELITE_CODERS_CLIP.png\n",
      "‚úÖ Saved: 110_ELITE_CODERS_CLIP.png\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import torch\n",
    "import clip\n",
    "from PIL import Image\n",
    "import numpy as np\n",
    "import faiss\n",
    "\n",
    "# -------------------------------\n",
    "# Paths\n",
    "# -------------------------------\n",
    "BASE_DIR = r\"C:/Users/priya/OneDrive/Desktop/mediaval\"\n",
    "CSV_PATH = os.path.join(BASE_DIR, \"newsarticles.csv\")\n",
    "IMAGE_DIR = os.path.join(BASE_DIR, \"newsimages_25_v1.1\", \"newsimages\")\n",
    "FEATURE_DIR = os.path.join(BASE_DIR, \"features_batches\")\n",
    "\n",
    "# ‚ö° Change for submission\n",
    "GROUP_NAME = \"ELITE_CODERS\"\n",
    "APPROACH_NAME = \"CLIP\"\n",
    "OUTPUT_DIR = os.path.join(BASE_DIR, f\"{GROUP_NAME}\", f\"RET_{APPROACH_NAME}_LARGE\")\n",
    "os.makedirs(OUTPUT_DIR, exist_ok=True)\n",
    "\n",
    "# -------------------------------\n",
    "# Load dataset and clean\n",
    "# -------------------------------\n",
    "df = pd.read_csv(\n",
    "    CSV_PATH,\n",
    "    header=None,\n",
    "    names=[\"article_id\", \"article_url\", \"article_title\", \"article_tags\", \"image_id\", \"image_url\"]\n",
    ")\n",
    "df = df.dropna(subset=['image_id', 'article_title']).copy()\n",
    "df['article_tags'] = df['article_tags'].fillna(\"\")\n",
    "df['image_id'] = df['image_id'].astype(str).str.strip()\n",
    "print(f\"‚úÖ Loaded {len(df)} rows after cleaning\")\n",
    "\n",
    "# -------------------------------\n",
    "# Step 1: Load precomputed features\n",
    "# -------------------------------\n",
    "all_features, all_ids = [], []\n",
    "\n",
    "for file in os.listdir(FEATURE_DIR):\n",
    "    if file.startswith(\"features_\") and file.endswith(\".npy\"):\n",
    "        feats = np.load(os.path.join(FEATURE_DIR, file))\n",
    "        ids_file = file.replace(\"features_\", \"ids_\").replace(\".npy\", \".csv\")\n",
    "        ids = pd.read_csv(os.path.join(FEATURE_DIR, ids_file)).squeeze()\n",
    "        if hasattr(ids, \"tolist\"):\n",
    "            ids = ids.tolist()\n",
    "        else:\n",
    "            ids = [ids]\n",
    "        ids = [str(i).strip() for i in ids]  # ensure string\n",
    "        all_features.append(feats)\n",
    "        all_ids.extend(ids)\n",
    "\n",
    "combined_features = np.vstack(all_features).astype(\"float32\")\n",
    "image_id_list = all_ids\n",
    "print(f\"‚úÖ Loaded {combined_features.shape[0]} feature vectors\")\n",
    "\n",
    "# -------------------------------\n",
    "# Step 2: Build FAISS Index\n",
    "# -------------------------------\n",
    "dim = combined_features.shape[1]\n",
    "index = faiss.IndexFlatIP(dim)\n",
    "index.add(combined_features)\n",
    "print(f\"‚öôÔ∏è FAISS index built with {index.ntotal} vectors\")\n",
    "\n",
    "# -------------------------------\n",
    "# Step 3: Run retrieval for ALL queries\n",
    "# -------------------------------\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "model, preprocess = clip.load(\"ViT-B/32\", device=device)\n",
    "\n",
    "K = 1\n",
    "unique_titles = df['article_title'].unique()\n",
    "print(f\"\\nüîÑ Running retrieval for {len(unique_titles)} queries...\")\n",
    "\n",
    "missing_images = []\n",
    "\n",
    "for query_title in unique_titles:\n",
    "    query = query_title.strip()\n",
    "    if not query:\n",
    "        continue\n",
    "\n",
    "    # Encode query\n",
    "    text = clip.tokenize([query[:200]]).to(device)\n",
    "    with torch.no_grad():\n",
    "        q_feat = model.encode_text(text)\n",
    "        q_feat /= q_feat.norm(dim=-1, keepdim=True)\n",
    "\n",
    "    # Search in FAISS\n",
    "    search_vector = q_feat.cpu().numpy().astype(\"float32\")\n",
    "    D, I = index.search(search_vector, K)\n",
    "\n",
    "    for score, idx in zip(D[0], I[0]):\n",
    "        if idx == -1:\n",
    "            continue\n",
    "        image_id = image_id_list[idx]\n",
    "        row = df[df['image_id'] == str(image_id)].iloc[0]\n",
    "\n",
    "        # Check for jpg or png\n",
    "        img_path_jpg = os.path.join(IMAGE_DIR, f\"{image_id}.jpg\")\n",
    "        img_path_png = os.path.join(IMAGE_DIR, f\"{image_id}.png\")\n",
    "\n",
    "        if os.path.exists(img_path_jpg):\n",
    "            img_path = img_path_jpg\n",
    "        elif os.path.exists(img_path_png):\n",
    "            img_path = img_path_png\n",
    "        else:\n",
    "            missing_images.append(image_id)\n",
    "            print(f\"‚ùå Image not found: {image_id}\")\n",
    "            continue\n",
    "\n",
    "        # Load + resize + save\n",
    "        try:\n",
    "            image = Image.open(img_path).convert(\"RGB\")\n",
    "            image = image.resize((460, 260))\n",
    "            save_name = f\"{row['article_id']}_{GROUP_NAME}_{APPROACH_NAME}.png\"\n",
    "            save_path = os.path.join(OUTPUT_DIR, save_name)\n",
    "            image.save(save_path, format=\"PNG\")\n",
    "            print(f\"‚úÖ Saved: {save_name}\")\n",
    "        except Exception as e:\n",
    "            print(f\"‚ùå Error saving {img_path}: {e}\")\n",
    "\n",
    "print(\"üéØ Retrieval complete!\")\n",
    "if missing_images:\n",
    "    print(f\"‚ö†Ô∏è Missing {len(missing_images)} images. See list below:\")\n",
    "    print(missing_images)\n",
    "print(\"Submission files ready in:\", OUTPUT_DIR)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "809a1738-615f-4859-ab2d-8882f69fded9",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
